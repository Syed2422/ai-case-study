# Claude by Anthropic

  **Anthropic** is a company with a clear mission to make AI safer for everyone. It was founded by Dario Amodei, and the company focuses on AI safety rather than just building the most powerful models. It's a public benefit company, meaning it’s designed to make a positive impact on society, not just make profits. They have raised over $7 billion dollars and is one of the biggest Ai companies out there. 
 
  The company operates in the **generative AI industry**, where it's up against famous rivals like OpenAI’s ChatGPT and Google’s Gamini. However, Anthropic differentiates itself by prioritizing safety, as shown by their Responsible Scaling Policy, which shows how they use a deployment risk classification and a containment risk classification program. As of now, their models are not risky, but they suspect in the future, all these models that are being made will be deployed will be too risky. This policy helps mitigate against disastrously advanced Ai which threatens humanity's safety and future. 
 
  One interesting direction Anthropic could take is developing a **therapy-focused AI**. This could offer a therapeutic service, making the AI more specialized and useful for those seeking mental health support. It can get answers by either scraping the web or by intentional training by its creators, they can help solve peoples psychological distress and help them as a Ai therapist. 

  Addendum: 
    [Link 1](https://time.com/6980000/anthropic/) , 
    [Link 2](https://www.anthropic.com/) ,
    [Link 3](https://www.anthropic.com/news/anthropics-responsible-scaling-policy) , 
    [Link 4](https://www-cdn.anthropic.com/1adf000c8f675958c2ee23805d91aaade1cd4613/responsible-scaling-policy.pdf) . 
